{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a74f90bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for TSLA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 1256 days of data\n",
      "\n",
      "First few rows of data:\n",
      "Price            Close        High         Low        Open     Volume\n",
      "Ticker            TSLA        TSLA        TSLA        TSLA       TSLA\n",
      "Date                                                                 \n",
      "2021-02-22  238.166672  256.166656  236.733337  254.213333  111809100\n",
      "2021-02-23  232.946671  237.869995  206.333328  220.710007  199820700\n",
      "2021-02-24  247.339996  248.333328  231.389999  237.283340  110301000\n",
      "2021-02-25  227.406662  245.736664  223.526672  242.050003  117071700\n",
      "2021-02-26  225.166672  235.566666  219.836670  233.333328  123267600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Part 1: Import Libraries and Fetch Data\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Select stock \n",
    "stock_symbol = 'TSLA'  # Tesla\n",
    "# stock_symbol = 'AAPL'  # Apple\n",
    "# stock_symbol = 'MSFT'  # Microsoft\n",
    "# stock_symbol = 'GOOGL' # Google\n",
    "\n",
    "print(f\"Downloading data for {stock_symbol}...\")\n",
    "\n",
    "# Download historical data\n",
    "stock_data = yf.download(stock_symbol, period='5y')\n",
    "print(f\"Downloaded {len(stock_data)} days of data\")\n",
    "print(\"\\nFirst few rows of data:\")\n",
    "print(stock_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c052ce0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating features for prediction...\n",
      "Dataset shape after feature engineering: (1236, 14)\n",
      "\n",
      "Features created:\n",
      "Price      High_Low_Pct Close_Open_Pct        MA_5 Volatility\n",
      "Ticker                                                       \n",
      "Date                                                         \n",
      "2021-03-19     4.979612       1.278991  226.310663  14.015235\n",
      "2021-03-22     4.607460      -2.131207  223.781329   6.549333\n",
      "2021-03-23     3.064215      -2.013999  222.799997   6.792841\n",
      "2021-03-24     6.014886      -5.635494  218.030664   8.488300\n",
      "2021-03-25     5.621574       4.468192  217.179330   8.666120\n"
     ]
    }
   ],
   "source": [
    "# Part 2: Create Features for Prediction\n",
    "print(\"\\nCreating features for prediction...\")\n",
    "\n",
    "# Create a copy of the data\n",
    "df = stock_data.copy()\n",
    "\n",
    "# Create target variable (next day's closing price)\n",
    "df['Next_Close'] = df['Close'].shift(-1)\n",
    "\n",
    "# Create additional features\n",
    "df['High_Low_Pct'] = (df['High'] - df['Low']) / df['Close'] * 100\n",
    "df['Close_Open_Pct'] = (df['Close'] - df['Open']) / df['Open'] * 100\n",
    "\n",
    "# Create rolling averages\n",
    "df['MA_5'] = df['Close'].rolling(window=5).mean()\n",
    "df['MA_10'] = df['Close'].rolling(window=10).mean()\n",
    "df['MA_20'] = df['Close'].rolling(window=20).mean()\n",
    "\n",
    "# Create volatility features\n",
    "df['Volatility'] = df['Close'].rolling(window=10).std()\n",
    "\n",
    "# Create lag features (previous days' prices)\n",
    "df['Prev_Close'] = df['Close'].shift(1)\n",
    "df['Prev_Volume'] = df['Volume'].shift(1)\n",
    "\n",
    "# Drop NaN values\n",
    "df = df.dropna()\n",
    "\n",
    "print(f\"Dataset shape after feature engineering: {df.shape}\")\n",
    "print(\"\\nFeatures created:\")\n",
    "print(df[['High_Low_Pct', 'Close_Open_Pct', 'MA_5', 'Volatility']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f120cc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing data for training...\n",
      "Training data size: 988 days\n",
      "Testing data size: 248 days\n",
      "\n",
      "Features used: Open, High, Low, Volume, High_Low_Pct, Close_Open_Pct, MA_5, MA_10, MA_20, Volatility, Prev_Close, Prev_Volume\n"
     ]
    }
   ],
   "source": [
    "# Part 3: Prepare Data for Training\n",
    "print(\"\\nPreparing data for training...\")\n",
    "\n",
    "# Select features for prediction\n",
    "feature_columns = ['Open', 'High', 'Low', 'Volume', \n",
    "                   'High_Low_Pct', 'Close_Open_Pct',\n",
    "                   'MA_5', 'MA_10', 'MA_20', \n",
    "                   'Volatility', 'Prev_Close', 'Prev_Volume']\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df['Next_Close']\n",
    "\n",
    "# Split the data (chronologically)\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "print(f\"Training data size: {len(X_train)} days\")\n",
    "print(f\"Testing data size: {len(X_test)} days\")\n",
    "print(f\"\\nFeatures used: {', '.join(feature_columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2f8583d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "TRAINING LINEAR REGRESSION MODEL\n",
      "==================================================\n",
      "\n",
      "Linear Regression Results:\n",
      "Training MSE: 93.55\n",
      "Testing MSE: 162.23\n",
      "Training R² Score: 0.9785\n",
      "Testing R² Score: 0.9698\n",
      "Mean Absolute Error: 9.90\n",
      "\n",
      "Top 5 Important Features (Linear Regression):\n",
      "          Feature  Coefficient\n",
      "5  Close_Open_Pct     1.763555\n",
      "4    High_Low_Pct     1.007472\n",
      "2             Low     0.713098\n",
      "0            Open     0.471429\n",
      "9      Volatility     0.188678\n"
     ]
    }
   ],
   "source": [
    "# Part 4: Train Linear Regression Model\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING LINEAR REGRESSION MODEL\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create and train Linear Regression model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "lr_train_pred = lr_model.predict(X_train)\n",
    "lr_test_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "lr_train_mse = mean_squared_error(y_train, lr_train_pred)\n",
    "lr_test_mse = mean_squared_error(y_test, lr_test_pred)\n",
    "lr_train_r2 = r2_score(y_train, lr_train_pred)\n",
    "lr_test_r2 = r2_score(y_test, lr_test_pred)\n",
    "lr_mae = mean_absolute_error(y_test, lr_test_pred)\n",
    "\n",
    "print(\"\\nLinear Regression Results:\")\n",
    "print(f\"Training MSE: {lr_train_mse:.2f}\")\n",
    "print(f\"Testing MSE: {lr_test_mse:.2f}\")\n",
    "print(f\"Training R² Score: {lr_train_r2:.4f}\")\n",
    "print(f\"Testing R² Score: {lr_test_r2:.4f}\")\n",
    "print(f\"Mean Absolute Error: {lr_mae:.2f}\")\n",
    "\n",
    "# Feature importance for Linear Regression\n",
    "lr_coefficients = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Coefficient': lr_model.coef_\n",
    "}).sort_values('Coefficient', key=abs, ascending=False)\n",
    "print(\"\\nTop 5 Important Features (Linear Regression):\")\n",
    "print(lr_coefficients.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4dc41e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "TRAINING RANDOM FOREST MODEL\n",
      "==================================================\n",
      "\n",
      "Random Forest Results:\n",
      "Training MSE: 18.75\n",
      "Testing MSE: 290.89\n",
      "Training R² Score: 0.9957\n",
      "Testing R² Score: 0.9458\n",
      "Mean Absolute Error: 12.52\n",
      "\n",
      "Top 5 Important Features (Random Forest):\n",
      "           Feature  Importance\n",
      "1             High    0.578869\n",
      "2              Low    0.390806\n",
      "0             Open    0.009402\n",
      "10      Prev_Close    0.004757\n",
      "5   Close_Open_Pct    0.004212\n"
     ]
    }
   ],
   "source": [
    "# Part 5: Train Random Forest Model\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING RANDOM FOREST MODEL\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create and train Random Forest model\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "rf_train_pred = rf_model.predict(X_train)\n",
    "rf_test_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "rf_train_mse = mean_squared_error(y_train, rf_train_pred)\n",
    "rf_test_mse = mean_squared_error(y_test, rf_test_pred)\n",
    "rf_train_r2 = r2_score(y_train, rf_train_pred)\n",
    "rf_test_r2 = r2_score(y_test, rf_test_pred)\n",
    "rf_mae = mean_absolute_error(y_test, rf_test_pred)\n",
    "\n",
    "print(\"\\nRandom Forest Results:\")\n",
    "print(f\"Training MSE: {rf_train_mse:.2f}\")\n",
    "print(f\"Testing MSE: {rf_test_mse:.2f}\")\n",
    "print(f\"Training R² Score: {rf_train_r2:.4f}\")\n",
    "print(f\"Testing R² Score: {rf_test_r2:.4f}\")\n",
    "print(f\"Mean Absolute Error: {rf_mae:.2f}\")\n",
    "\n",
    "# Feature importance for Random Forest\n",
    "rf_importance = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "print(\"\\nTop 5 Important Features (Random Forest):\")\n",
    "print(rf_importance.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d05113d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "MODEL COMPARISON\n",
      "==================================================\n",
      "\n",
      "Model Performance Comparison:\n",
      "            Model  Train MSE   Test MSE  Train R²  Test R²       MAE\n",
      "Linear Regression  93.551872 162.225815  0.978511 0.969764  9.902914\n",
      "    Random Forest  18.750051 290.890834  0.995693 0.945783 12.516761\n",
      "\n",
      "✅ Linear Regression performs better on test data!\n"
     ]
    }
   ],
   "source": [
    "# Part 6: Compare Models\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "comparison_data = {\n",
    "    'Model': ['Linear Regression', 'Random Forest'],\n",
    "    'Train MSE': [lr_train_mse, rf_train_mse],\n",
    "    'Test MSE': [lr_test_mse, rf_test_mse],\n",
    "    'Train R²': [lr_train_r2, rf_train_r2],\n",
    "    'Test R²': [lr_test_r2, rf_test_r2],\n",
    "    'MAE': [lr_mae, rf_mae]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Determine better model\n",
    "better_model = 'Random Forest' if rf_test_r2 > lr_test_r2 else 'Linear Regression'\n",
    "print(f\"\\n✅ {better_model} performs better on test data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10507f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 7: Plot Actual vs Predicted Prices\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PLOTTING RESULTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle(f'{stock_symbol} Stock Price Prediction Results', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Linear Regression - Training\n",
    "axes[0, 0].plot(y_train.values[:200], label='Actual', alpha=0.7)\n",
    "axes[0, 0].plot(lr_train_pred[:200], label='Predicted', alpha=0.7)\n",
    "axes[0, 0].set_title('Linear Regression - Training (First 200 days)')\n",
    "axes[0, 0].set_xlabel('Days')\n",
    "axes[0, 0].set_ylabel('Price ($)')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Linear Regression - Testing\n",
    "axes[0, 1].plot(y_test.values, label='Actual', alpha=0.7)\n",
    "axes[0, 1].plot(lr_test_pred, label='Predicted', alpha=0.7)\n",
    "axes[0, 1].set_title('Linear Regression - Testing')\n",
    "axes[0, 1].set_xlabel('Days')\n",
    "axes[0, 1].set_ylabel('Price ($)')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Random Forest - Training\n",
    "axes[1, 0].plot(y_train.values[:200], label='Actual', alpha=0.7)\n",
    "axes[1, 0].plot(rf_train_pred[:200], label='Predicted', alpha=0.7)\n",
    "axes[1, 0].set_title('Random Forest - Training (First 200 days)')\n",
    "axes[1, 0].set_xlabel('Days')\n",
    "axes[1, 0].set_ylabel('Price ($)')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Random Forest - Testing\n",
    "axes[1, 1].plot(y_test.values, label='Actual', alpha=0.7)\n",
    "axes[1, 1].plot(rf_test_pred, label='Predicted', alpha=0.7)\n",
    "axes[1, 1].set_title('Random Forest - Testing')\n",
    "axes[1, 1].set_xlabel('Days')\n",
    "axes[1, 1].set_ylabel('Price ($)')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
